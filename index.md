# Special Session on Situated Dialogue with Virtual Agents and Robots

## Overview

Recent technologies have brought conversational robots out of the lab and into the homes and workplaces of real users. Dialogue is now actively taking place between people and agents to operate, navigate, visualize, and interact in physical or virtual spaces. *Situated dialogue* distinguishes itself from other forms of dialogue in that it (1) takes place in an environment (real or simulated), (2) refers to the shared surroundings of interlocutors, and (3) involves an embodied agent (e.g., a robot or device). There is a growing need for bi-directional dialogue work to be showcased that supports the body of research on language grounding, vision, and language, as well as dialogue that will allow situated agents, like robots, to ask for clarification and provide updates on their internal states.

**Prior Special Sessions and Workshops***

- [RoboDial 2018, part of SigDial, Melbourne, Australia](robodial2018.md)

## Schedule (subject to change; times are in MDT (-6))

| 4:00 pm  | Introduction to Special Session                                                                                                      |              |
| 4:05 pm  | [It's About Time: Turn-Entry Timing For Situated Human-Robot Dialogue](https://www.sigdial.org/files/workshops/conference21/pdf/2020.sigdial-1.12.pdf)                                                                 | Felix Gervits, Ravenna Thielstrom, Antonio Roque and Matthias Scheutz                              |
| 4:17 pm  | [Learning Word Groundings from Humans Facilitated by Robot Emotional Displays](https://www.sigdial.org/files/workshops/conference21/pdf/2020.sigdial-1.13.pdf)                                                         | David McNeill and Casey Kennington                                                                 |
| 4:29 pm  | [Learning and Reasoning for Robot Dialog and Navigation Tasks](https://www.sigdial.org/files/workshops/conference21/pdf/2020.sigdial-1.14.pdf)                                                                         | Keting Lu, Shiqi Zhang, Peter Stone and Xiaoping Chen                                              |
| 4:41 pm  | [An Attentive Listening System with Android ERICA: Comparison of Autonomous and WOZ Interactions](https://www.sigdial.org/files/workshops/conference21/pdf/2020.sigdial-1.15.pdf)                                      | Koji Inoue, Divesh Lala, Kenta Yamamoto, Shizuka Nakamura, Katsuya Takanashi and Tatsuya Kawahara  |
| 5:00 pm  | Live Q/A Sessions for Demo Papers (presentations will be simultaneously live streamed)                                               |                                                                                                    |
| 5:00 pm  | [A Spoken Dialogue System for Spatial Question Answering in a Physical Blocks World](https://www.sigdial.org/files/workshops/conference21/pdf/2020.sigdial-1.16.pdf)                                                   | Georgiy Platonov, Lenhart Schubert, Benjamin Kane and Aaron Gindi                                  |
| 5:10 pm  | [rrSDS: Towards a Robot-ready Spoken Dialogue System](https://www.sigdial.org/files/workshops/conference21/pdf/2020.sigdial-1.17.pdf)                                                                                 | Casey Kennington, Daniele Moro, Lucas Marchand, Jake Carns, and David McNeill                      |
| 5:30 pm  | Live Q/A Session for Special Session Papers                                                                                          |                                                                                                    |
| 6:15 pm  | [A multimodal corpus of Human-Human and Human-Robot conversations including synchronized behavioral and neurophysiological recordings](A_multimodal_corpus_of_Human-Human_and_Human-Robot_conversations.pdf) | Thierry Chaminade                                                                                  |
| 6:20 pm  | [Grounding Robot Dialogue in Environment Sensors to help Elderly in Activities of Daily Living](Grounding_Human-Robot_Dialogue_in_Environment_Sensors_to_helpElderly_in_Activities_of_Daily_Living.pdf)                                       | Ifrah Idrees, Stefanie Tellex, Momotaz Begum                                                       |
| 6:25 pm  | [Dialog as a Vehicle for Lifelong Learning](Dialog_as_a_Vehicle_for_Lifelong_Learning.pdf)                                                                                            | Aishwarya Padmakumar, Raymond Mooney                                                               |
| 6:30 pm  | [Situated Multimodal Control of a Mobile Robot: Navigation through a Virtual Environment](Situated_Multimodal_Control_of_a_Mobile_Robot__Navigation_through_a_Virtual_Environment.pdf)                                              | Katherine Krajovic, Nikhil Krishnaswamy, Nathaniel J. Dimick, R. Pito Salas, and James Pustejovsky |
| 6:35 pm  | [Towards meaningful, grounded conversations with intelligent agents](Towards_meaningful_grounded_conversations_with_intelligent_agents.pdf)                                                                   | Alexandros Papangelis and Stefan Ultes

## Note on COVID-19

SIGDIAL will be held virtually, July 1-3. The Robodial Special Session will likewise be held virtually.

## Call for Papers

Recent technologies have brought conversational robots out of the lab and into the homes and workplaces of real users. Dialogue is now actively taking place between people and agents to operate, navigate, visualize, and interact in physical or virtual spaces. *Situated dialogue* distinguishes itself from other forms of dialogue in that it (1) takes place in an environment (real or simulated), (2) refers to the shared surroundings of interlocutors, and (3) involves an embodied agent (e.g., a robot or device). There is a growing need for bi-directional dialogue work to be showcased that supports the body of research on language grounding, vision, and language, as well as dialogue that will allow situated agents, like robots, to ask for clarification and provide updates on their internal states.

Our objectives in this special session are to showcase recent and ongoing work on situated dialogue, and to identify paths forward in this space from research across communities including dialogue, robotics, virtual agents, computer vision, NLP, and AI. The special session will feature oral presentations and a poster session. We welcome submissions on any topic related to situated dialogue, including but not limited to:

- Interaction studies with smart-home devices and virtual agents
- Learning from demonstration through natural language dialogue
- Explainable AI in physical and virtual spaces
- Representations of physical surroundings / world modeling to support grounded communication
- Embodied visual question answering and/or generation
- Empirical studies of human-robot dialogue (Wizard-of-Oz based, simulated, or semi-autonomous)
- Computational models of dialogue management and/or turn-taking with physical or virtual agents
- Methods of building or leveraging common ground with physical agents in real-world or simulated environments
- Corpora of situated dialogue (Wizard-of-Oz based, simulated, or semi-autonomous)
- Corpus analysis of situated dialogue
- Multimodal information processing to support dialogue (including speech, gaze, gesture)
- Physical embodiment, voice, or personification of robots and its effect on human-robot dialogue
- Communicating feedback from robots using affordances in addition to speech
- Machine learning methods for embodied dialogue systems
- Dialogue-based collaborative human-robot interaction
- Spoken language generation for situated dialogue
- Spoken language / speech processing technologies to support dialogue

Researchers may choose to submit:

- *Long papers and short papers* will present original research and go through the same peer review process by the SIGdial program committee as papers submitted to the main SIGdial track. These papers will appear in the main SIGdial proceedings and are presented with the main track. Long papers must be no longer than eight pages, including title, text, figures and tables, along with two additional pages for example discourses or dialogues and algorithms, and an extra page is allowed in the final version to address reviewers' comments. Short papers should be no longer than four pages including title, text, figures and tables, along with one additional page for example discourses or dialogues and algorithms, and an extra page is allowed in the final version to address reviewers' comments. An unlimited number of pages are allowed for references. 
- *Late-breaking and work-in-progress papers* will showcase ongoing work and focused, relevant contributions. Submissions need not present original work. Late-breaking and work-in-progress papers should be no longer than four pages including title, text, figures and tables, and references. These will be reviewed by the special session organizers and posted on the special session website. These papers will be presented as lightning talks or posters during the session. Authors will retain the copyright to their work so that they may submit to other venues as their work matures.
- *Position papers* will give voice to authors who wish to take a position on a topic listed above or the field of spoken, situated dialogue on robots at large. Submissions need not present original work. These will be reviewed by the special session organizers and posted on the special session website.  These papers will be presented as lightning talks or posters during the session. Authors will retain the copyright to their work so that they may submit to other venues.


### Important Dates

**Long and short paper submission deadline: abstracts and titles: March 6; final submission March 11**
To submit a long or short paper, please go to the SIGdial 2020 START page (https://www.softconf.com/l/sigdial2020/). When submitting, indicate “Special Session Paper (RoboDial 2.0)” under the “Submission Type” category. All long and short submissions must follow the SIGdial 2020 format. Following the SigDial timeline, you are required to complete the title, authors, and abstracts by the 6th, but you can make updates to the PDF submission until the 11th. 

**Late-breaking and work-in-progress paper deadline: June 9** 
To submit a late-breaking or work-in-progress paper, please email a 2-4 page PDF (including references) formatted using the SIGdial 2020 format guidelines, to: robodial@googlegroups.com by June 9 You will receive a confirmation of your submission and notification before the Early Bird Registration deadline. 

**Position paper deadline: June 9** 
To submit a position paper, please email a 4-6 page PDF (including references) formatted using the SIGdial 2020 format guidelines, to: robodial@googlegroups.com by June 9. You will receive a confirmation of your submission and notification before the Early Bird Registration deadline. 

**List of Organizers**
- Jose David Lopes, Heriot Watt University
- Stephanie Lukin, Army Research Lab
- Matthew Marge, Army Research Lab
- Vikram Ramanarayanan, Educational Testing Service
- Matthias Scheutz, Tufts University
- Casey Kennington, Boise State University
- Cynthia Matuszek, University of Maryland, Baltimore County

**Contact**: robodial@googlegroups.com

  
