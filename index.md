# Special Session on Physically Situated Dialogue
	
July 12, 2018<br>**Poster Session**: 13:30 - 14:30<br>**Talks and Panel**: 15:00 - 17:15

## Overview

Recent technologies have brought conversational robots out of the lab and into the homes and workplaces of real users. Dialogue is now actively taking place with robots and other smart devices to understand, operate, navigate, and manipulate physical space. _Physically situated dialogue_ distinguishes itself from other forms of dialogue in that it (1) takes place in a physical space, (2) refers to the shared surroundings of dialogue partners, and (3) involves a physical agent that can make actions in the world. There is a growing need for showcasing bi-directional dialogue work that draws on language grounding, models of vision and language, as well as dialogue that allows physically situated agents to ask for clarification and provide updates on their internal states.

## Schedule

| **Posters**<br>13:30 - 14:30 | _A Situated Dialogue System for Learning Structural Concepts in Blocks World_<br>Ian Perera, James Allen, Choh Man Teng, Lucian Galescu<br><br>_Pardon the Interruption: Managing Turn-Taking through Overlap Resolution in Embodied Artificial Agents_<br>Felix Gervits, Matthias Scheutz<br><br>_Consequences and Factors of Stylistic Differences in Human-Robot Dialogue_<br>Stephanie Lukin, Kimberly Pollard, Claire Bonial, Matthew Marge, Cassidy Henry, Ron Artstein, David Traum, Clare Voss<br><br>_Turn-Taking Strategies for Human-Robot Peer-Learning Dialogue_<br>Ranjini Das, Heather Pon-Barry |
| **Full paper presentations**<br>15:00 - 16:15 | _Predicting Perceived Age: Both Language Ability and Appearance are Important_<br>Sarah Plane, Ariel Marvasti, Tyler Egan, Casey Kennington<br><br>_Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog_<br>Jiaping Zhang, Tiancheng Zhao, Zhou Yu<br><br>_Language-Guided Adaptive Perception for Efficient Grounded Communication with Robotic Manipulators in Cluttered Environments_<br>Siddharth Patki, Thomas Howard |
| **LBR lightning talks**<br>16:15 - 16:45 | [Embodied Question Answering](embodiedqa_robodial.pdf)<br>Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, Dhruv Batra<br><br>[Jointly Improving Parsing and Perception for Natural Language Commands through Human-Robot Dialog](robodial-jesse.pdf)<br>Jesse Thomason, Aishwarya Padmakumar, Jivko Sinapov, Nick Walker, Yuqian Jiang, Harel Yedidsion, Justin Hart, Peter Stone, Raymond J. Mooney<br><br>[Experiments in Proactive Symbol Grounding for Efficient Physically Situated Human-Robot Dialogue](robodial_arkin_wip.pdf)<br>Jacob Arkin, Thomas Howard |
| **Panel Discussion**<br>16:45 - 17:15 | Thomas Howard, Casey Kennington, Ian Perera, Heather Pon-Barry, David Traum |

## Call for Papers

Our objectives in this special session are to showcase recent and ongoing work on physically situated dialogue, and to identify paths forward in this space from research across communities including dialogue, robotics, computer vision, NLP, and AI. The special session will feature presentations, a poster session, and a panel discussion comprising a mix of experts in the topic area. We welcome submissions on any topic related to physically situated dialogue, including but not limited to:

 - Interaction studies with smart-home devices
 - Learning from demonstration through natural language dialogue
 - Explainable AI in physical spaces
 - Representations of physical surroundings / world modeling to support grounded communication
 - Embodied visual question answering and/or generation
 - Empirical studies of human-robot dialogue (Wizard-of-Oz based, simulated, or semi-autonomous)
 - Computational models of dialogue management and/or turn-taking with physical agents
 - Methods of building or leveraging common ground with physical agents in real-world or simulated environments
 - Corpora of physically situated dialogue (Wizard-of-Oz based or otherwise)
 - Multimodal information processing to support dialogue (including speech, gaze, gesture)
 - Physical embodiment, voice, or personification of robots and their effects on human-robot dialogue
 - Communicating feedback from robots using affordances in addition to speech
 - Spoken language generation for physically situated dialogue
	
Researchers may choose to submit:

 - **Long papers and short papers** will present original research and go through the regular SIGdial peer review process by the general SIGdial program committee. These papers will appear in the main SIGdial proceedings and are presented with the main track. Long papers must be no longer than eight pages, including title, text, figures and tables, along with two additional pages for example discourses or dialogues and algorithms. Short papers should be no longer than four pages including title, text, figures and tables, along with one additional page for example discourses or dialogues and algorithms. An unlimited number of pages are allowed for references.
 - **Late-breaking and work-in-progress papers** will showcase ongoing work and focused, relevant contributions. Submissions need not present original work and are limited to four pages including references. These will be reviewed by the special session organizers and posted on the special session website. These papers will be presented as lightning talks or posters during the session. Authors will retain the copyright to their work so that they may submit to other venues as their work matures.
		
### Long and short paper deadline: March 11

_Final pdf due March 18_

To submit a long or short paper, please go to the <a href="http://www.sigdial.org/workshops/conference19/">SIGDIAL 2018 main page</a> for conference submissions (deadline March 11). When submitting, indicate "Physically Situated Dialogue" as the candidate special session. All long and short submissions must follow the SIGDIAL 2018 format.

### Late-breaking and work-in-progress paper deadline: June 10

To submit a late-breaking or work-in-progress paper, please email a 2-4 page PDF (including references) formatted using the SIGDIAL 2018 format guidelines, to: <a href="mailto:robodial@googlegroups.com">robodial@googlegroups.com</a> by June 10. Submissions should be non-anonymized.
  
## Important Dates

| March 11, 2018 | Long and short paper initial submission deadline<br>(<a href="http://www.sigdial.org/workshops/conference19/">SIGDIAL submission system</a>) |
| March 18, 2018 | Final pdf due for long and short paper submission |
| April 20, 2018 | SIGDIAL notification of acceptance |
| May 13, 2018   | Camera-ready submission deadline |
| June 10, 2018 | Late-breaking and work-in-progress submission deadline<br>(Email directly to: <a href="mailto:robodial@googlegroups.com">robodial@googlegroups.com</a>) |
| July 12-14, 2018 | SIGDIAL conference |

## Organizers

<a href="https://www.microsoft.com/en-us/research/people/sandrist/">Sean Andrist</a>, Microsoft Research<br>
<a href="https://users.soe.ucsc.edu/~slukin">Stephanie Lukin</a>, Army Research Lab<br>
<a href="http://www.cs.cmu.edu/~mrmarge">Matthew Marge</a>, Army Research Lab<br>
<a href="https://jessethomason.com">Jesse Thomason</a>, University of Texas at Austin<br>
<a href="http://www.cs.cmu.edu/~zhouyu">Zhou Yu</a>, University of California, Davis
